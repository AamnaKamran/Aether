{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcQGoRs3EIagFPdIQw8Bdn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AamnaKamran/Aether/blob/main/Update_KG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib\n",
        "!pip install SPARQLWrapper\n",
        "!pip install owlready2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FOLFElfdBBq",
        "outputId": "da3b715c-5e17-4c29-ec92-85e6dedfe377"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.3/500.3 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from rdflib) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from rdflib) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from isodate->rdflib) (1.15.0)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-6.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: rdflib>=6.1.1 in /usr/local/lib/python3.8/dist-packages (from SPARQLWrapper) (6.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from isodate->rdflib>=6.1.1->SPARQLWrapper) (1.15.0)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting owlready2\n",
            "  Downloading Owlready2-0.39.tar.gz (25.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=Owlready2-0.39-cp38-cp38-linux_x86_64.whl size=22260905 sha256=b6a546e2f7e407704b65d959d9bcb89ff7a38085536704adb0d0965464c34559\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/16/5f/a0bfc34a8f7682cbd6b4d9cb1436c0a0a04ac3579394d7e28a\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph, URIRef, Literal, BNode, Namespace\n",
        "from rdflib.namespace import FOAF, XMLNS, XSD, RDF, RDFS, OWL\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "os.chdir('/content/')\n",
        "\n",
        "# find if directory is '../Megascans Library/Downloaded/UAssets' or '../Megascans Library/UAssets'\n",
        "def trigger_update(path_to_asset_folder): \n",
        "  \n",
        "  \n",
        "  g = Graph()\n",
        "  g.parse('Populated_Assets_KG.ttl', format = \"ttl\")\n",
        "  n = Namespace(\"http://www.semanticweb.org/szm/megascan-assets-ontology#\")\n",
        "\n",
        "\n",
        "  qres = g.query(\n",
        "    \"\"\"\n",
        "      PREFIX mega:<http://www.semanticweb.org/szm/megascan-assets-ontology#>\n",
        "      SELECT ?s ?aID ?aName WHERE {\n",
        "      ?s mega:assetID ?aID.\n",
        "      ?s mega:assetName ?aName.\n",
        "       FILTER BOUND(?aID)\n",
        "    }\"\"\")\n",
        "  \n",
        "\n",
        "  cur_KG_assets = set()    \n",
        "  for row in qres:\n",
        "    # check asset IDs currently loaded in the assets' KG - they have IDs same as their folder and json file names\n",
        "    cur_KG_assets.add(row.aID.toPython())\n",
        "  cur_KG_assets = list(cur_KG_assets)\n",
        "\n",
        "  # cur_dir = os.chdir(path_to_asset_folder)\n",
        "  # Get list of all asset folder names, then iteratively go through them.\n",
        "  \n",
        "  \n",
        "  downloaded_asset_folder_names = os.listdir(path_to_asset_folder)\n",
        "  downloaded_assets_path_dict = {}\n",
        "  for folder_name in downloaded_asset_folder_names:\n",
        "    if len(os.listdir(str(path_to_asset_folder)+str(folder_name)+'/')) != 0 and str(folder_name)+'.json' in os.listdir(str(path_to_asset_folder)+str(folder_name)+'/'):\n",
        "      downloaded_assets_path_dict[folder_name] = str(path_to_asset_folder)+str(folder_name)+'/'+str(folder_name)+'.json'\n",
        "\n",
        "\n",
        "# DONE  ########  - test if a new asset is correctly recognized (that's downloaded, but not added to KG)\n",
        "# DOING ########  - then add only new assets to KG \n",
        "\n",
        "  print(downloaded_assets_path_dict)\n",
        "\n",
        "  new_asset_paths_dict = {}\n",
        "  for key,value in downloaded_assets_path_dict.items():\n",
        "    if key not in cur_KG_assets:\n",
        "      new_asset_paths_dict[key] = value\n",
        "  print(\"Assets not yet added to KG:\", new_asset_paths_dict)\n",
        "\n",
        "trigger_update( '/content/Megascans Library/Downloaded/UAssets/')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za5zN188dJQQ",
        "outputId": "9058882a-8630-4db7-b869-e6605897f551"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "{'tlesfb1fa': '/content/Megascans Library/Downloaded/UAssets/tlesfb1fa/tlesfb1fa.json', 'uknjfevga': '/content/Megascans Library/Downloaded/UAssets/uknjfevga/uknjfevga.json', 'tk4tcfhfa': '/content/Megascans Library/Downloaded/UAssets/tk4tcfhfa/tk4tcfhfa.json', 'uknkaffaw': '/content/Megascans Library/Downloaded/UAssets/uknkaffaw/uknkaffaw.json', 'extra_test': '/content/Megascans Library/Downloaded/UAssets/extra_test/extra_test.json'}\n",
            "Assets not yet added to KG: {'extra_test': '/content/Megascans Library/Downloaded/UAssets/extra_test/extra_test.json'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Namespace\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "# retrieve asset lists' file. If downloaded asset folder contains assts besides those mentioned in assets list file, update KG\n",
        "\n",
        "# Set for colab env.\n",
        "path_to_asset_files = '/content/Megascans Library/UAssets/'\n",
        "\n",
        "def update_KG(path_to_asset_files):\n",
        "  # cur_dir = os.chdir(path_to_json_files)\n",
        "  # # Get list of all asset folder names, then iteratively go through them.\n",
        "  # assets_path_dict = {}\n",
        "  \n",
        "  # asset_folder_names = os.listdir(path_to_asset_files)\n",
        "  # asset_folder_paths = []\n",
        "  # for asset_name in asset_folder_names:\n",
        "  #   asset_folder_path.append(cur_dir+asset_name)\n",
        "  # print(\"Updated assets folder path: \", asset_folder_path)\n",
        "  # for i in range in asset_folder_path:\n",
        "  #   if asset_\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  n = Namespace(\"http://www.semanticweb.org/szm/megascan-assets-ontology#\")  \n",
        "  json_files = [pos_json for pos_json in os.listdir(path_to_asset_files) if pos_json.endswith('.json')]\n",
        "\n",
        "  for asset_file in json_files:\n",
        "\n",
        "    # Open asset file\n",
        "    f = open(asset_file)\n",
        "    data = json.load(f) # json file loaded as dictionary\n",
        "\n",
        "    # Create asset and set asset name\n",
        "    name = data[\"name\"]     # obtain name of asset, convert it to RDF format literal\n",
        "    name_processed = re.sub(\"[^a-zA-Z0-9]\", \"_\", name)\n",
        "    print(\"Created asset name = \", name)\n",
        "    print(name_processed)\n",
        "    asset = URIRef(str(n)+\"Asset_\"+name_processed)  # create a resource in the Assets Knowledge Graph (KG)\n",
        "    print(\"Asset = \", asset)\n",
        "    g.add((asset, RDF.type, n.Asset))\n",
        "    g.add((asset, n.assetName, Literal(name, datatype=XSD.string)))     # Add triple to KG: {new Asset resource, nameRelation (from schema), name obtained from asset file}\n",
        "\n",
        "    try:\n",
        "      # Set asset ID\n",
        "      id = Literal(str(data[\"id\"]), datatype=XSD.string)\n",
        "      g.add((asset, n.assetID, id))\n",
        "      print(\"Added assetID = \", id)\n",
        "    except:\n",
        "      print(\"No asset ID specified for asset\", asset)\n",
        "\n",
        "    try:\n",
        "      # Set asset search tags\n",
        "      tags = data[\"tags\"]\n",
        "      print(\"number of tags = \", len(tags))\n",
        "      for t in tags:\n",
        "        tag = Literal(str(t), datatype=XSD.string)\n",
        "        g.add((asset, n.assetTag, tag))\n",
        "        print(\"Added tag = \", tag)\n",
        "\n",
        "    except:\n",
        "      print(\"No search tags specified for asset\", asset)\n",
        "\n",
        "    try:\n",
        "      # Create category individuals and set their names, then assign asset categories\n",
        "      categories = data[\"categories\"]\n",
        "      print(\"number of categories = \", len(categories))\n",
        "      for c in categories:\n",
        "        category = Literal(c, datatype=XSD.string)\n",
        "        g.add((asset, n.assetCategory, category))\n",
        "        print(\"Adding category = \", category)\n",
        "\n",
        "    except:\n",
        "      print(\"No categories specified for asset\", asset)\n",
        "\n",
        "\n",
        "    properties = data[\"properties\"]\n",
        "    print(\"number of properties = \", len(properties))\n",
        "    for prop in properties:\n",
        "      key = list(prop.keys())[0]\n",
        "      value = list(prop.values())[0]\n",
        "      print(\"prop['key'] = \"  , prop[\"key\"])\n",
        "      print(\"prop['value'] = \"  , prop[\"value\"])\n",
        "\n",
        "    try:\n",
        "      properties = data[\"properties\"]\n",
        "      print(\"number of properties = \", len(properties))\n",
        "      for prop in properties:\n",
        "        key = list(prop.keys())[0]\n",
        "        value = list(prop.values())[0]\n",
        "\n",
        "        print(\"prop['key'] = \"  , prop[\"key\"])\n",
        "        print(\"prop['value'] = \"  , prop[\"value\"])\n",
        "\n",
        "        print(\"prop key = \", key)\n",
        "        if prop[\"key\"] == \"size\":\n",
        "          # print(value, Literal(value))\n",
        "          if prop[\"value\"] == \"tiny\":\n",
        "            g.add((asset, n.assetSize, n.tiny))\n",
        "            print(\"Added asset size = \", n.tiny)\n",
        "          elif prop[\"value\"] == \"small\":\n",
        "            g.add((asset, n.assetSize, n.small))\n",
        "            print(\"Added asset size = \", n.small)\n",
        "          elif prop[\"value\"] == \"medium\":\n",
        "            g.add((asset, n.assetSize, n.medium))\n",
        "            print(\"Added asset size = \", n.medium)\n",
        "          elif prop[\"value\"] == \"large\":\n",
        "            g.add((asset, n.assetSize, n.large))\n",
        "            print(\"Added asset size = \", n.large)\n",
        "          else:\n",
        "            g.add((asset, n.assetSize, n.extra_large))\n",
        "            print(\"Added asset size = \", n.extra_large)\n",
        "\n",
        "        elif prop[\"key\"] == \"age\":\n",
        "          age = Literal(prop[\"value\"], datatype=XSD.string)\n",
        "          g.add((asset, n.assetAge, age))\n",
        "          print(\"Added asset age = \", age)\n",
        "\n",
        "    except:\n",
        "      print(\"No properties specified for asset\", asset)\n",
        "\n",
        "    try:\n",
        "      # Set asset average color\n",
        "      avg_color = Literal(str(data[\"averageColor\"]), datatype=XSD.string)\n",
        "      g.add((asset, n.assetAvgColor, avg_color))\n",
        "      print(\"Added asset average color = \", avg_color)\n",
        "    except:\n",
        "      print(\"No asset avg color specified for asset\", asset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    unique_biomes = set()\n",
        "    unique_regions = set()\n",
        "\n",
        "    # Create biome individuals if not alrady created, then link to assets\n",
        "    try:\n",
        "      biome = URIRef(str(n)+\"Biome_\"+data[\"environment\"][\"biome\"])\n",
        "      if biome not in unique_biomes:\n",
        "        g.add((biome, RDF.type, n.Biome))\n",
        "        biome_name = Literal(data[\"environment\"][\"biome\"], datatype=XSD.string)\n",
        "        g.add((biome, n.biomeName, biome_name))\n",
        "        unique_biomes.add(biome)\n",
        "        print(\"Added new biome to graph: \", biome)\n",
        "      g.add((asset, n.assetEnvironmentBiome, biome))\n",
        "      print((\"Added asset's biome = \", biome))\n",
        "    except:\n",
        "      print(\"No asset biome found for asset\", asset)\n",
        "\n",
        "\n",
        "\n",
        "    # Create region individuals, then link to assets\n",
        "    try:\n",
        "      region = URIRef(str(n)+\"Region_\"+data[\"environment\"][\"region\"])\n",
        "      if region not in unique_regions:\n",
        "        g.add((region, RDF.type, n.Region))\n",
        "        region_name = Literal(data[\"environment\"][\"region\"], datatype=XSD.string)\n",
        "        g.add((region, n.regionName, region_name))    \n",
        "        unique_regions.add(region)\n",
        "        print(\"Added new region to graph: \", region)\n",
        "      g.add((asset, n.assetEnvironmentRegion, region))\n",
        "      print((\"Added asset's region = \", region))\n",
        "    except:\n",
        "      print(\"No asset region found for asset\", asset)\n",
        "\n",
        "    print(len(g))\n",
        "\n",
        "    f.close()\n",
        "\n",
        "  \n",
        "  g.serialize(destination='Populated_Assets_KG.ttl', format='turtle')\n"
      ],
      "metadata": {
        "id": "s3FS77JZJJPZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def trigger_KG_update(path_to_asset_folder)\n",
        "  cur_dir = os.chdir(path_to_asset_folder)\n",
        "  # Get list of all asset folder names, then iteratively go through them.\n",
        "  \n",
        "  \n",
        "  downloaded_asset_folder_names = os.listdir(path_to_asset_files)\n",
        "  downloaded_asset_folder_paths = []\n",
        "  for asset_name in downloaded_asset_folder_names:\n",
        "    downloaded_asset_folder_paths.append(cur_dir+asset_name)\n",
        "  # print(\"Updated assets folder path: \", downloaded_asset_folder_paths)\n",
        "  downloaded_assets_path_dict = dict(zip(downloaded_asset_folder_names, downloaded_asset_folder_paths))\n",
        "\n",
        "# read asset list file. For any asset not mentioned in the assets' list file but present in the downloaded assets' folder, add it to KG\n",
        "with open('assets_file.txt', assets_file):\n",
        "  for key,value in downloaded_assets_path_dict:\n",
        "    \n",
        " \n"
      ],
      "metadata": {
        "id": "RdHLzL6wcXps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfcbxcfdmGYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
